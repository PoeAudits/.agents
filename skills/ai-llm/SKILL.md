---
name: ai-llm
description: AI and LLM skills including prompt engineering and evaluation strategies. This skill should be used when working with AI/LLM projects, implementing "prompt optimization", "LLM evaluation", or "AI testing strategies".
---

# AI/LLM Skills

A collection of skills for building, optimizing, and evaluating LLM applications. Each skill focuses on a specific aspect of working with large language models in production.

## Activation Triggers

- Designing or optimizing prompts for LLM applications
- Measuring LLM application performance and quality
- Implementing evaluation frameworks for AI systems
- Testing LLM outputs for consistency and reliability
- Building production prompt templates with structured outputs
- Establishing baselines and tracking AI performance over time
- Debugging unexpected model behavior or inconsistent outputs

## Quick Routing

**Need to test LLM performance or measure quality?** → `llm-evaluation`

**Need to optimize prompts or improve outputs?** → `prompt-engineering-patterns`

## Skill Map

| Skill | Covers |
|-------|--------|
| [llm-evaluation](references/llm-evaluation/SKILL.md) | Comprehensive evaluation strategies using automated metrics, human feedback, and benchmarking |
| [prompt-engineering-patterns](references/prompt-engineering-patterns/SKILL.md) | Advanced prompt engineering techniques for maximum performance, reliability, and controllability |
